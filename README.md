# AI Music Generation Project

This project uses an LSTM neural network implemented in Keras to generate music.

## Project Overview

The AI Music Generation Project aims to create original musical compositions using machine learning techniques. By leveraging Long Short-Term Memory (LSTM) neural networks, we can train models to understand and generate musical patterns.

## Features

- LSTM-based neural network for music generation
- Implemented using Keras and TensorFlow
- Ability to generate MIDI files as output

## Getting Started

### Prerequisites

- Python 3.8 or higher
- TensorFlow 2.x
- Keras
- Music21 library

### Installation

1. Clone the repository:
   ```
   git clone https://github.com/yourusername/ai-music-project.git
   cd ai-music-project
   ```

2. Create a virtual environment:
   ```
   python -m venv ai-music-env
   source ai-music-env/bin/activate  # On Windows, use `ai-music-env\Scripts\activate`
   ```

3. Install the required packages:
   ```
   pip install -r requirements.txt
   ```

## Usage

This project allows you to train and generate music for various instruments using MIDI files. Here's how to use it:

### Training the Model

1. Prepare your MIDI files:
   - Organize MIDI files for each instrument into separate directories (e.g., `midi_bass`, `midi_drums`, `midi_lead`, `midi_songs`).
   - Ensure each directory contains MIDI files specific to that instrument.

2. Modify the filepath in `lstm.py`:
   - Open `lstm.py` and locate the `get_notes()` function.
   - Change the filepath in the following line to point to your desired MIDI files:
     ```python
     for file in glob.glob("midi_songs/*.mid"):
     ```
     Replace `"midi_songs/*.mid"` with the path to your instrument-specific MIDI files (e.g., `"midi_bass/*.mid"`).

3. Train the model:
   ```
   python lstm.py
   ```
   This will train the neural network using the MIDI files in the specified directory and save the model weights.

### Generating Music

1. Modify the filepath in `predict.py`:
   - Open `predict.py` and locate the `generate()` function.
   - Update the filepath to match the one used in `lstm.py`:
     ```python
     with open('data/notes', 'rb') as filepath:
     ```
     Change `'data/notes'` to match the instrument you're generating (e.g., `'data/notes_bass'`).

2. Generate a new MIDI file:
   ```
   python predict.py
   ```
   This will use the trained model to generate a new MIDI file named `test_output.mid` in the project directory.


### Creating a Complete AI-Generated Composition

1. Generate MIDI files for multiple instruments using the steps above.

2. Import the generated MIDI files into a Digital Audio Workstation (DAW) such as Ableton Live.

3. Arrange and combine the different instrument tracks in your DAW to create a complete composition.

4. Apply effects, adjust timing, and add any additional elements to refine the final track.

5. Export your finished composition from the DAW.

Note: While the individual MIDI files are generated by AI, the final composition created by arranging and modifying these files in a DAW is considered your original work and is copyrighted by you (or the user who creates it). If you are using this unedited for commercial purposes, you must give credit to the original author (me, @ezequielcutin).

The quality and style of the generated music will depend on the MIDI files used for training. Experiment with different input files, instruments, and DAW arrangements to achieve various results and create unique AI-assisted compositions.

## Project Structure

The project is organized as follows:

- `lstm.py`: Contains the main LSTM model for training on MIDI files.
- `predict.py`: Generates new MIDI files using the trained model.
- `fetch_midis.sh`: Shell script to fetch sample MIDI files for training.
- `requirements.txt`: Lists all Python dependencies for the project.
- `midi_songs/`: Directory containing MIDI files for training (piano).
- `midi_bass/`: Directory for bass MIDI files.
- `midi_drums/`: Directory for drum MIDI files.
- `midi_lead/`: Directory for lead instrument MIDI files.
- `data/`: Directory for storing processed note data.
- `model improvements/`: Directory for storing model weights during training.

Key functions in the code:
- `train_network()` in `lstm.py`: Main function for training the LSTM model.
- `generate()` in `predict.py`: Main function for generating new MIDI files.
- `get_notes()` in `lstm.py`: Extracts notes and chords from MIDI files.
- `create_network()` in both files: Defines the LSTM neural network structure.
- `prepare_sequences()` in both files: Prepares input data for the neural network.
- `create_midi()` in `predict.py`: Converts generated notes to a MIDI file.

To train on different instruments, modify the filepath in `get_notes()` function of `lstm.py` and update the corresponding filepath in `predict.py`.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
Can find MIDI mappings at [https://www.cprato.com/en/midi/all/release-date](https://www.cprato.com/en/midi/all/release-date)

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- This project is based on the article "How to Generate Music using a LSTM Neural Network in Keras" by Sigurður Skúli, published on December 7, 2017 in Towards Data Science.
- The original tutorial is part of the "Build your own X" repository hosted by codecrafters-io on GitHub: [https://github.com/codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x)
- Note: While inspired by the original tutorial, this project has been modified and expanded upon. The code in this repository is not an exact copy of the original model and includes custom changes and improvements.
